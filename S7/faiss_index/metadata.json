[
  {
    "doc_id": "3bfd6fbf-996e-4dde-9ff0-cde1418354d6",
    "title": "Healing Aura",
    "source_type": "text",
    "chunk": "The Healing Power of Your Aura Have you ever walked into a room and felt the energy shift? Do people confide in you, feel comforted by your presence, or leave your company feeling rejuvenated and inspired? If so, you may possess a powerful, healing aura \u2014 a natural gift that resonates deeply with others and transforms the energy around you. Your aura, the electromagnetic energy field that surrounds you, is a reflection of your spiritual, emotional, and physical state. When your energy is pure, balanced, and high-vibrational, it has the power to heal not just yourself but also those around you. But how do you know if you have this gift?",
    "chunk_id": "3bfd6fbf-996e-4dde-9ff0-cde1418354d6_0",
    "url": null
  },
  {
    "doc_id": "c954b211-95e4-4790-99b6-3f53ae0aec36",
    "title": "Mlflow",
    "source_type": "pdf",
    "chunk": "Blog / The MLFlow-Airflow-Kubernetes Makeshift Monster: How Your DIY ML Stack Became Your Biggest Bottleneck The MLFlow-Airflow- Kubernetes Makeshift Monster: How Your DIY ML Stack Became Your Biggest Bottleneck by Drazen Dodik | on April 28, 2025 Ever watched a horror movie where the scientist creates a monster with the best intentions? That's the ML infrastructure story playing out in companies everywhere today. 5/4/25, 8:58 PM The MLFlow-Airflow-Kubernetes Makeshift Monster: How Your DIY ML Stack Became Your Biggest Bottleneck https://valohai.com/blog/the-mlflow-airflow-kubernets-makeshift-monster/ 1/9 It All Starts With Good Intentions Your team begins with basic needs. Version control? Git. Experiment tracking? MLflow. Need to scale? Maybe SageMaker or a Kubernetes cluster because someone on the team thinks it \"sounds fun.\" (Spoiler: managing Kubernetes is many things, but \"fun\" isn't one of them.) Each decision makes perfect sense when viewed in isolation. But soon, your tool sprawl grows out of control: One team prefers MLflow, another adopts Weights & Biases You need to separate projects between teams, so now you're maintaining multiple MLflow instances Your orchestration tool forces you to completely rewrite code with special decorators and platform-specific patterns Finding and fixing issues becomes nearly impossible when jobs run across various environments, tools and dashboards Every dataset version lives in its own world, with no clear connection to the models trained on it Pretty soon, your team isn't building models\u2014they're gluing together tools, writing custom integrations, and maintaining a patchwork of systems just to keep things running. The Hidden Business Costs You Can't Ignore This isn't just a technical nuisance.",
    "chunk_id": "c954b211-95e4-4790-99b6-3f53ae0aec36_0",
    "url": null
  },
  {
    "doc_id": "c954b211-95e4-4790-99b6-3f53ae0aec36",
    "title": "Mlflow",
    "source_type": "pdf",
    "chunk": "trained on it Pretty soon, your team isn't building models\u2014they're gluing together tools, writing custom integrations, and maintaining a patchwork of systems just to keep things running. The Hidden Business Costs You Can't Ignore This isn't just a technical nuisance. It's actively hurting your business in ways that might not show up clearly on a dashboard but are devastatingly real: Productivity Drain: Data scientists spend hours or even days recreating past runs because they can't easily find or reproduce previous experiments. \"Which version of the data did I use again? Where did I save those parameters?\" Resource Waste: Infrastructure sits idle or runs at the wrong size because nobody has visibility across systems. You're paying premium prices for GPU instances that might be running at 15% utilization. 5/4/25, 8:58 PM The MLFlow-Airflow-Kubernetes Makeshift Monster: How Your DIY ML Stack Became Your Biggest Bottleneck https://valohai.com/blog/the-mlflow-airflow-kubernets-makeshift-monster/ 2/9 All-Hands Debugging Sessions: When something breaks in production, it takes the entire team to figure out what went wrong. One person checks pipeline logs, another investigates the data sources, a third verifies the infrastructure, and a fourth tries to determine if it was a code change or parameter tweak that broke things. Communication Overhead: Team members spend excessive time explaining their work to each other because there's no shared source of truth. \"No, I used that version of the model with this dataset on those parameters\u2026and oh yeah, I had to change this Docker configuration\" Onboarding Paralysis: New team members take months to become productive. As one VP told me, \"I",
    "chunk_id": "c954b211-95e4-4790-99b6-3f53ae0aec36_1",
    "url": null
  },
  {
    "doc_id": "c954b211-95e4-4790-99b6-3f53ae0aec36",
    "title": "Mlflow",
    "source_type": "pdf",
    "chunk": "truth. \"No, I used that version of the model with this dataset on those parameters\u2026and oh yeah, I had to change this Docker configuration\" Onboarding Paralysis: New team members take months to become productive. As one VP told me, \"I have a dream where data scientists don't become integration engineers\u2014they're productive on Day 1.\" Instead, they waste weeks mastering your custom tool soup rather than building models that matter. The Hidden Vulnerability: Your ML Stack's Dangerous Bus Factor Every DIY ML stack eventually creates its \"tribal knowledge keepers\"\u2014those few team members who truly understand how everything fits together. Maybe they're the ones who stitched together MLflow with Airflow using a combination of Bash scripts, Python glue code, and sheer determination. Or perhaps they're the only ones who can explain how model versioning actually works when you're running retraining from a cron job inside a Kubernetes cluster. At first, this person is a hero. The go-to expert. The team's Rosetta Stone for translating between Terraform configs, pipeline YAMLs, and Dockerfiles. But over time, the hero's cape starts to feel unbearably heavy. They're pulled into every debugging session. Asked to unblock every new hire's onboarding. Pinged at all hours for tribal knowledge that was never documented because, well, there was never time. And when they finally take a vacation\u2014or worse, leave the company\u2014your entire ML operation teeters like a Jenga tower after one too many bad moves. Even if they are still around, the costs silently accumulate: 5/4/25, 8:58 PM The MLFlow-Airflow-Kubernetes Makeshift Monster: How Your DIY ML",
    "chunk_id": "c954b211-95e4-4790-99b6-3f53ae0aec36_2",
    "url": null
  },
  {
    "doc_id": "c954b211-95e4-4790-99b6-3f53ae0aec36",
    "title": "Mlflow",
    "source_type": "pdf",
    "chunk": "vacation\u2014or worse, leave the company\u2014your entire ML operation teeters like a Jenga tower after one too many bad moves. Even if they are still around, the costs silently accumulate: 5/4/25, 8:58 PM The MLFlow-Airflow-Kubernetes Makeshift Monster: How Your DIY ML Stack Became Your Biggest Bottleneck https://valohai.com/blog/the-mlflow-airflow-kubernets-makeshift-monster/ 3/9 Velocity grinds to a halt because work piles up behind one or two knowledge gatekeepers Morale plummets as those experts burn out from being the default 24/7 help desk Resentment builds when newer team members feel like they're navigating a maze where someone keeps moving the walls You didn't hire brilliant machine learning engineers to babysit pipeline configurations and personally train every new joiner on your homegrown infrastructure. But without proper abstraction, documentation, and unified platform support, that's exactly what they become\u2014glorified integration support specialists rather than ML pioneers. The Real Casualty: Experimentation Paralysis Your team doesn't stop experimenting\u2014they just bypass your infrastructure entirely. When connecting to environments, orchestrating jobs, and tracking results requires serious effort across multiple systems, they retreat to their local machines. The result? Fewer iterations, safer choices, and valuable insights lost to \"shadow ML\" that never makes it into your official systems. When Production Issues Strike The real nightmare happens when production issues arise. Instead of quickly identifying and fixing the problem, you need: Someone to check the pipeline logs in system Airflow Someone else to investigate the data in AWS S3 A third person to verify the compute infrastructure in AWS EC2 A fourth to determine if the issue was caused by a code",
    "chunk_id": "c954b211-95e4-4790-99b6-3f53ae0aec36_3",
    "url": null
  },
  {
    "doc_id": "c954b211-95e4-4790-99b6-3f53ae0aec36",
    "title": "Mlflow",
    "source_type": "pdf",
    "chunk": "to check the pipeline logs in system Airflow Someone else to investigate the data in AWS S3 A third person to verify the compute infrastructure in AWS EC2 A fourth to determine if the issue was caused by a code change or a parameter change through MLFlow By the time you've diagnosed the issue, you've burned days of collective engineering time and delayed critical fixes. With each person only understanding their specific piece of the puzzle, you're seeing: Critical ML projects stalled by resource or expertise bottlenecks Production models failing without clear warning signs 5/4/25, 8:58 PM The MLFlow-Airflow-Kubernetes Makeshift Monster: How Your DIY ML Stack Became Your Biggest Bottleneck https://valohai.com/blog/the-mlflow-airflow-kubernets-makeshift-monster/ 4/9 Teams forced to start from scratch because they can't reproduce previous work Workarounds and security gaps as teams try to sidestep limitations What Good Actually Looks Like A unified ML platform shouldn't require your team to become infrastructure experts. It should: Work with minimal code changes (you shouldn't need to completely rewrite code with special decorators or platform-specific patterns) Reduce compute costs by surfacing GPU usage metrics, empowering teams to optimize resource allocation naturally without becoming infrastructure experts Enable both one-click and programmatic model promotion with automated tracking Manage all ML environments from a single interface Provide intelligent orchestration with unified control The ideal platform fades into the background\u2014it's infrastructure that enables rather than distracts. Breaking Free of Your Homemade Monster You don't need to throw everything away and start over. But it's worth stepping back to assess honestly: is your tool stack serving",
    "chunk_id": "c954b211-95e4-4790-99b6-3f53ae0aec36_4",
    "url": null
  },
  {
    "doc_id": "c954b211-95e4-4790-99b6-3f53ae0aec36",
    "title": "Mlflow",
    "source_type": "pdf",
    "chunk": "platform fades into the background\u2014it's infrastructure that enables rather than distracts. Breaking Free of Your Homemade Monster You don't need to throw everything away and start over. But it's worth stepping back to assess honestly: is your tool stack serving your team, or is your team serving the tool stack? If your engineers are spending more time maintaining connections between systems, figuring out how to access the right logs, tracking down the right metrics, or managing job orchestration than actually building models\u2014you've created a monster. A Better Way Forward Oh, shocker. It's a Valohai blog promoting Valohai. All the points above make sense no matter what MLOps solution you choose, but I genuinely believe Valohai offers 5/4/25, 8:58 PM The MLFlow-Airflow-Kubernetes Makeshift Monster: How Your DIY ML Stack Became Your Biggest Bottleneck https://valohai.com/blog/the-mlflow-airflow-kubernets-makeshift-monster/ 5/9 the best path forward: Accelerated delivery: Cut project setup time with pre-built templates and slash time-to- production Cost optimization: Eliminate redundant runs with automatic experiment detection and job reuse Resource efficiency: Surface real-time GPU usage metrics that enable teams to naturally optimize resource allocation Team onboarding: Get new data scientists productive in days rather than weeks with minimal platform-specific knowledge Seamless debugging: Track every decision from data to model with complete lineage and robust traceability (and with the ability to attach a debugger, yesss!) Infrastructure flexibility: Deploy anywhere with the same workflow\u2014cloud, on-prem, or hybrid environments No Bulldozers Needed: Upgrading Without Starting From Scratch You're thinking: \"We've spent years building this stack. Migrating sounds like setting cash on fire.\" I get it.",
    "chunk_id": "c954b211-95e4-4790-99b6-3f53ae0aec36_5",
    "url": null
  },
  {
    "doc_id": "c954b211-95e4-4790-99b6-3f53ae0aec36",
    "title": "Mlflow",
    "source_type": "pdf",
    "chunk": "debugger, yesss!) Infrastructure flexibility: Deploy anywhere with the same workflow\u2014cloud, on-prem, or hybrid environments No Bulldozers Needed: Upgrading Without Starting From Scratch You're thinking: \"We've spent years building this stack. Migrating sounds like setting cash on fire.\" I get it. But escaping your homemade ML monster doesn't require a scorched- earth approach. Valohai doesn't force you to rewrite your codebase with some proprietary SDK. No magical decorators. No mysteries on \u201cis it me, or Valohai?\u201d Instead, Valohai aims to adapt to your existing workflow. Your existing scripts? Keep them. Folder organization? Just as you like it. The difference? Everything suddenly has lineage, automation, and reproducibility\u2014without the duct tape and prayers/crystals. Still skeptical? I would too after battling MLflow-Airflow-Kubernetes integration hell. So here's my challenge: give our team two hours. That's it. (I mean, I'll need a brief first on what your project is and how it's structured. I'm not a mind reader\u2026 yet!) Two hours on a screenshare, and together we\u2019ll live-code migrate your first job and pipeline into Valohai. No sleight of hand. Just your actual workflows made instantly 5/4/25, 8:58 PM The MLFlow-Airflow-Kubernetes Makeshift Monster: How Your DIY ML Stack Became Your Biggest Bottleneck https://valohai.com/blog/the-mlflow-airflow-kubernets-makeshift-monster/ 6/9 traceable. Don't believe it? Test me. Book a demo and join us for a different kind of ML infrastructure experience. Your future self (and your sanity) will thank you. I have read and agree to Valohai's privacy policy. 5/4/25, 8:58 PM The MLFlow-Airflow-Kubernetes Makeshift Monster: How Your DIY ML Stack Became Your Biggest Bottleneck https://valohai.com/blog/the-mlflow-airflow-kubernets-makeshift-monster/ 7/9 The Hidden",
    "chunk_id": "c954b211-95e4-4790-99b6-3f53ae0aec36_6",
    "url": null
  },
  {
    "doc_id": "c954b211-95e4-4790-99b6-3f53ae0aec36",
    "title": "Mlflow",
    "source_type": "pdf",
    "chunk": "infrastructure experience. Your future self (and your sanity) will thank you. I have read and agree to Valohai's privacy policy. 5/4/25, 8:58 PM The MLFlow-Airflow-Kubernetes Makeshift Monster: How Your DIY ML Stack Became Your Biggest Bottleneck https://valohai.com/blog/the-mlflow-airflow-kubernets-makeshift-monster/ 7/9 The Hidden Reproducibility Crisis Killing Your ML Team's Productivity (And Your Budget) Drazen Dodik / April 30, 2025 How to manage massive datasets in Valohai Tomi Kokkonen / February 19, 2025 2024 in Review (Part 1) Tarek Oraby / December 18, 2024 Boosting Velocity in Data Science Teams: A Practical Guide Tarek Oraby / November 27, 2024 Stop wasting your GPUs with Valohai's Dynamic GPU Allocation Tarek Oraby / November 20, 2024 Valohai's Audit Log: Traceability built for AI governance Tarek Oraby / November 06, 2024 AMD GPU Performance for LLM Inference: A Deep Dive Eero Laaksonen / October 31, 2024 Simplify and automate the machine learning model lifecycle Tarek Oraby / September 18, 2024 3 things to look forward to in MLOps (or maybe 4) Alexander Rozhkov / September 11, 2024 Stop waiting for your training data to download (again) Tarek Oraby / September 04, 2024 Solve the GPU shortage and control cloud costs: Valohai\u2019s partnership with OVHcloud Toni Per\u00e4m\u00e4ki / August 28, 2024 Save time and avoid recomputation with Pipeline Step Caching Tarek Oraby / August 20, 2024 Platform + Solutions + Resources + Other + 5/4/25, 8:58 PM The MLFlow-Airflow-Kubernetes Makeshift Monster: How Your DIY ML Stack Became Your Biggest Bottleneck https://valohai.com/blog/the-mlflow-airflow-kubernets-makeshift-monster/ 8/9 Nobody Cares... + Featured Success Stories + Sign up to our newsletter",
    "chunk_id": "c954b211-95e4-4790-99b6-3f53ae0aec36_7",
    "url": null
  },
  {
    "doc_id": "c954b211-95e4-4790-99b6-3f53ae0aec36",
    "title": "Mlflow",
    "source_type": "pdf",
    "chunk": "20, 2024 Platform + Solutions + Resources + Other + 5/4/25, 8:58 PM The MLFlow-Airflow-Kubernetes Makeshift Monster: How Your DIY ML Stack Became Your Biggest Bottleneck https://valohai.com/blog/the-mlflow-airflow-kubernets-makeshift-monster/ 8/9 Nobody Cares... + Featured Success Stories + Sign up to our newsletter Your work email \u00a9 2025 Valohai 5/4/25, 8:58 PM The MLFlow-Airflow-Kubernetes Makeshift Monster: How Your DIY ML Stack Became Your Biggest Bottleneck https://valohai.com/blog/the-mlflow-airflow-kubernets-makeshift-monster/ 9/9",
    "chunk_id": "c954b211-95e4-4790-99b6-3f53ae0aec36_8",
    "url": null
  },
  {
    "doc_id": "a8c1909913cad84bcbc9e8a82430255e",
    "title": "YOLO Blog #1: YOLO for Biomedical Images | by Johanna Jones | Medium",
    "source_type": "html",
    "chunk": "YOLO Blog #1: YOLO for Biomedical Images | by Johanna Jones | Medium Open in app Sign up Sign in Write Sign up Sign in YOLO Blog #1: YOLO for Biomedical Images The place of YOLO in object detection tasks for biomedical images Johanna Jones Follow 5 min read \u00b7 Jun 14, 2024 -- Listen Share Cell Counting and Detection are important tasks in medicine and biology, which aid pathologists in understanding how cells behave to diagnose disease. Traditionally, pathologists were counting and detecting cells manually but this can lead to a high level of error and subjectivity, which is not something we want in sensitive scenarios like disease diagnosis. Therefore, they have turned to deep learning to count and detect cells for them. Even so, these biomedical images present a number of challenges for the deep learning algorithms to learn and make predictions well. 3 Challenges presented to ML and DL algorithms Overlapped and clustered cells make it difficult for algorithms to properly segment the image and distinguish cell from cell. Weakly stained cells create difficulties for the model to distinguish artefact noise and the image background from the target cells. Diverse cell morphologies prevent the algorithm from generalising more broadly and making predictions. CNNs and other deep learning techniques are already being implemented within the field. However, these solutions are unique to the domain and have bespoke datasets ultimately, not offering a whole lot of generalisability within biomedicine. In this blog post, I want to touch on the existing studies that have used YOLO",
    "chunk_id": "a8c1909913cad84bcbc9e8a82430255e_0",
    "url": "https://medium.com/@johannajones00/yolo-blog-1-yolo-for-biomedical-images-b797be9704c2"
  },
  {
    "doc_id": "a8c1909913cad84bcbc9e8a82430255e",
    "title": "YOLO Blog #1: YOLO for Biomedical Images | by Johanna Jones | Medium",
    "source_type": "html",
    "chunk": "the field. However, these solutions are unique to the domain and have bespoke datasets ultimately, not offering a whole lot of generalisability within biomedicine. In this blog post, I want to touch on the existing studies that have used YOLO and the gaps they have. I also want to touch on the different YOLO models currently out there and their key features. What is YOLO? No, its not the risk inspiring and motivating YOLO (You Only live Once\u2026 But in the words of Dwight Schrute \u2018 False, you live every day. You only die once \u2019 but I digress), this YOLO is different. You Only Look Once, is a state of the art object detection algorithm that leverages CNNs to detect objects in real time. It is a single shot detector that passes an image through the CNN once, producing classifications and bounding boxes of the objects within that image. YOLO has demonstrated a high level of generalisability and versa- tility in a variety of domains such as security, crowd and trac monitoring, often out- performing Region-based CNNs and Single Shot detectors.First built in 2015, the framework has undergone continuous modifications and improvements to achieve better performance. As of June 2024, I believe YOLOv10 is the latest release. For the upcoming blogs, my focus will only be on YOLO versions 5, 8 and 9. In general there are three main components to YOLO\u2019s architecture YOLO basic architecture Backbone: The backbone is responsible for extracting valuable characteristics and then generating feature maps from the input image. A",
    "chunk_id": "a8c1909913cad84bcbc9e8a82430255e_1",
    "url": "https://medium.com/@johannajones00/yolo-blog-1-yolo-for-biomedical-images-b797be9704c2"
  },
  {
    "doc_id": "a8c1909913cad84bcbc9e8a82430255e",
    "title": "YOLO Blog #1: YOLO for Biomedical Images | by Johanna Jones | Medium",
    "source_type": "html",
    "chunk": "be on YOLO versions 5, 8 and 9. In general there are three main components to YOLO\u2019s architecture YOLO basic architecture Backbone: The backbone is responsible for extracting valuable characteristics and then generating feature maps from the input image. A CNN that has been extensively pre- trained on large image datasets is commonly used for the backbone. Popular choices for backbones include VGG16, ResNet50, CSP-Darknet53 and EffcientRep Neck: The neck is made up of two components; the Spatial Pyramid Pooling (SPP) and Path Aggregation Network (PAN). Both components work to combine the extracted feature maps generated by the backbone through a process of feature aggregation and propagate them to the head. Head : The head handles the aggregated features from the neck and makes predictions on the image relating to the bounding boxes coordinate estimates, classification scores class probabilities . Often, studies have tried different combinations of backbones, necks, and heads to investigate model speed, accuracy, and detection performance. YOLO heads are also interchangeable across different YOLO models. YOLO in Biomedical Images A list of related work where YOLO has been used detect cells. Existing studies relating to YOLO detecting on biomedical images revolve around assessing different model\u2019s speed and accuracy (see the above table). Nair (2021) deployed a YOLOv4 model for mitotic nuclei detection in breast cancer histopathological images. While a computationally efficient and reasonably fast, the study suffered in model performance when given pixel and colour normalised images and was deemed unsuitable for full scale deployment. In another study, Topuz (2023) deployed YOLO models",
    "chunk_id": "a8c1909913cad84bcbc9e8a82430255e_2",
    "url": "https://medium.com/@johannajones00/yolo-blog-1-yolo-for-biomedical-images-b797be9704c2"
  },
  {
    "doc_id": "a8c1909913cad84bcbc9e8a82430255e",
    "title": "YOLO Blog #1: YOLO for Biomedical Images | by Johanna Jones | Medium",
    "source_type": "html",
    "chunk": "breast cancer histopathological images. While a computationally efficient and reasonably fast, the study suffered in model performance when given pixel and colour normalised images and was deemed unsuitable for full scale deployment. In another study, Topuz (2023) deployed YOLO models V3, V5, V7 and V8 to compare how accurately each could detect mitosis cells as an indicator for lung cancer. Models V7 and V8 outperformed others in correctly detecting mitosis cells despite the data imbalance and low-quality input images. V7 and V8 exhibited higher performance due to a combination of higher image resolution processing, improved module innovations and new loss functions. Others have performed ablation studies to determine which components of YOLO\u2019s architecture yield the best detection results. Alam and Islam (2019) deployed a Tiny YOLO model to count and detect blood cells by replacing the primary backbone of the YOLO model with other CNN architectures like VGG-16, ResNet50 and Mobile Net. Results showed that the standalone Tiny YOLO drastically outper- formed the other CNN architectures and generalised well to unseen data sets. Yucel (2023) compared the performance of a YOLOv5 (baseline) to a YOLOv5 with a transformer mechanism (transformer) to detect mitosis cells in neuroendocrine tumours, with the aim of creating a high speed and accurate detector. Results showed that the transformer consistently detected more mitosis cells than the baseline and image augmen- tation techniques also boosted the transformer model\u2019s speed and accuracy. While these YOLO models have been chosen for their accuracy and speed, they do not explicitly address the challenges of overlapped cells,",
    "chunk_id": "a8c1909913cad84bcbc9e8a82430255e_3",
    "url": "https://medium.com/@johannajones00/yolo-blog-1-yolo-for-biomedical-images-b797be9704c2"
  },
  {
    "doc_id": "a8c1909913cad84bcbc9e8a82430255e",
    "title": "YOLO Blog #1: YOLO for Biomedical Images | by Johanna Jones | Medium",
    "source_type": "html",
    "chunk": "mitosis cells than the baseline and image augmen- tation techniques also boosted the transformer model\u2019s speed and accuracy. While these YOLO models have been chosen for their accuracy and speed, they do not explicitly address the challenges of overlapped cells, diverse cell morphologies or weakly stained cells. Therefore, I would like to see how different YOLO versions perform on a given dataset and the extent to which they can addresss those challenges. Summary of YOLO versions to date. In my next blog, I\u2019ll cover the dataset available and any EDA I performed. Stay tuned! Don\u2019t forget to YOLO :) All work is sourced from my paper : Analysis of different YOLO variants Yolo Object Detection Biomedical Data Science Deep Learning Follow Written by Johanna Jones 9 Followers \u00b7 7 Following I am a Masters Student, studying a Masters in Data Science. I am in my final year of study looking to explore new ideas and share them. Follow No responses yet Help Status About Careers Press Blog Privacy Rules Terms Text to speech",
    "chunk_id": "a8c1909913cad84bcbc9e8a82430255e_4",
    "url": "https://medium.com/@johannajones00/yolo-blog-1-yolo-for-biomedical-images-b797be9704c2"
  }
]